ants[1,]
ants10[1,]
ants10[1,3]
ants10[1,1]
ants10[1,]
ants10[,1]
?lapply
?ddply
??ddply
libraru(plyr)
library(plyr)
?ddply
?ldply
temp = list()
temp[[1]] = data.frame(x = 1:5, y = c('','','','','dfg'))
temp[[2]]] = data.frame(x = 6:10, y = c('','','','','afb'))
agedata = data.frame()
temp = list()
temp[[1]] = data.frame(x = 1:5, y = c('','','','','dfg'))
temp[[2]] = data.frame(x = 6:10, y = c('','','','','afb'))
temp
ldply(temp, summarise, c1 = mean(x), c2 = y[5])
letters
temp = factor(letters[c(1,2,3,2,3,4,2,4,1)])
temp
levels(temp)
temp[4]
c(1,2,3)
c('a','b', temp[3])
?t.test
b = c(13,24,19,10,21,17,13,15,17,24,23,21,19,20,24,21,24,13,19,21,15,22,10,23,20,23)
a = c(5,15,15,17,21,21,20,20,17,18,21,23,21,20,14,16,21,18,24,24,24,23,21,24,24,22)
t.test(a,b)
install.packages("vitae")
install.packages('scholar')
rm(list = ls())
view=View
library(phytools)
t = pbtree(5)
rm(list = ls())
view=View
library(ordinal)
data(wine)
head(wine)
str(wine)
fm1 = clmm2(rating ~ temp + contact, random = judge, data = wine)
fm2 = clmm2(rating ~ contact, random = judge, data = wine)
anova(fm1, fm2)
?clmm2
?clm2
clm2
chisq.test
?clmm2
# Dataset
data <- matrix( sample(seq(1,2000),200), ncol = 10 )
rownames(data) <- paste0("sample_" , seq(1,20))
colnames(data) <- paste0("variable",seq(1,10))
head(data)
head(data)
?hclust
install.packages("ggdag")
library(ggdag)
?ggdag
install.packages("dagitty")
dagify(m ~ x + y) %>%
tidy_dagitty() %>%
node_dconnected("x", "y", controlling_for = "m") %>%
ggplot(aes(
x = x,
y = y,
xend = xend,
yend = yend,
shape = adjusted,
col = d_relationship
)) +
geom_dag_edges(aes(end_cap = ggraph::circle(10, "mm"))) +
geom_dag_collider_edges() +
geom_dag_point() +
geom_dag_text(col = "white") +
theme_dag() +
scale_adjusted() +
expand_plot(expand_y = expansion(c(0.2, 0.2))) +
scale_color_viridis_d(
name = "d-relationship",
na.value = "grey85",
begin = .35
)
dag <- dagitty("dag {
y <- x <- z1 <- v -> z2 -> y
z1 <- w1 <-> w2 -> z2
x <- w1 -> y
x <- w2 -> y
x [exposure]
y [outcome]
}"
)
library(daggity)
library(dagitty)
dag <- dagitty("dag {
y <- x <- z1 <- v -> z2 -> y
z1 <- w1 <-> w2 -> z2
x <- w1 -> y
x <- w2 -> y
x [exposure]
y [outcome]
}"
)
tidy_dag <- tidy_dagitty(dag)
dag
ggdag(tidy_ggdag) + theme_dag()
x = (1:1000)/1000
y = x^2
plot(x=x,y=y)
y = (0.25+x)^2
plot(x=x,y=y)
y = (0.25-x)^2
plot(x=x,y=y)
x = (-500:500)/200
y = x^2
plot(x=x,y=y)
y = -0.25*x^2
plot(x=x,y=y)
y = 0.25*x^2
plot(x=x,y=y)
y = x^2
plot(x=x,y=y)
Sys.setlocale("LC_TIME", "C")
cat("Generated on:", format(Sys.time(), "%B %d, %Y - %H:%M:%S"))
# install packages if not yet installed
packages <- c("mgcv","itsadug","lme4","nloptr")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
install.packages(setdiff(packages, rownames(installed.packages())))
}
# load required packages
library(lme4) # for GCA
library(mgcv) # for GAMs
library(itsadug) # for plotting GAMs
install.packages('itsadug')
R.Version()
## >> loading up libraries; helper stuff
######
library(plyr)
library(lme4)
library(lmerTest)
library(emmeans)
library(ggplot2)
library(knitr)
library(stringdist)
install.packages(plyr)
install.packages('plyr')
install.packages('lme4')
install.packages("lme4")
install.packages("lmerTest")
install.packages("emmeans")
install.packages("ggplot2")
install.packages("knitr")
install.packages("stringdist")
library(xlsx)
--request
library(rJava)
install.packages('xlsReadWrite')
install.packages(levendist)
??levendist
install.packages(stringdist)
install.packages('stringdist')
library('stringdist')
prons = c('potu','vefa','liko','lewu','zura','varo')
verbs = c('hefo','dibu','fosi','tasu','nemi','jota')
?levendist
??levendist
??stringdist
stringdist('ab','cd',method = 'lv')
stringdist('ab','ad',method = 'lv')
stringdist('ab','adb',method = 'lv')
stringdist('ab','adbb',method = 'lv')
stringdist(prons,prons,method = 'lv')
stringdistmatrix(prons,prons,method = 'lv')
stringdistmatrix(verbs,verbs,method = 'lv')
stringdistmatrix(verbs,venglserbs,method = 'lv')
stringdistmatrix(verbs,engls,method = 'lv')
engls = c('play','wait','talk','draw','sing','walk')
stringdistmatrix(verbs,engls,method = 'lv')
temp = c('p+n+v','pn+v','p+n+v','pn_v','pn_v','p+n+v','p_n_v','p+n_v','pn_v','pn+v','pn_v','pn+v','p+n+v','pn_v','p+v','p+v','p_v','p+v','p+v','p+v','p+v','p_v','p+n_v','p_v','p+n+v','p+v','p+n+v','p+n_v','p+v','p_v','p_v','p+n+v','p_v','pn+v','p+n+v','p+n+v','p+n+v')
table(temp)
colnamesnames(table(temp))
colnames(table(temp))
str(table(temp))
names(table(temp))
names(table(temp))[2:7]
rep(names(table(temp))[2:7],4)
t2 = data.frame(cond = c(rep(names(table(temp))[2:7],48)),temp), finished =  c(rep(1,48*6),rep(0,length(temp))))
t2 = data.frame(cond = c(rep(names(table(temp))[2:7],48),temp), finished =  c(rep(1,48*6),rep(0,length(temp))))
View(t2)
table(t2$cond,t2$finished)
temp
grep('p_n_v',t2$cond)
t2[295,]
t2[295,] = NULL
t2 = t2[c(1:294,296:nrow(t2)),]
grep('p_n_v',t2$cond)
table(t2$cond,t2$finished)
t2$Verb = factor(ifelse(t2$cond %in% c('pn+v','p+n+v','p+v'), 'Concatenated', 'Isolated'), levels = c('Isolated','Concatenated'))
t2$Pronoun = factor(ifelse(t2$cond %in% c('pn+v','pn_v'), 'Fused', ifelse(t2$cond %in% c('p+n+v','p+n_v'), 'Agglutinated', 'No number')), levels = c('No number','Agglutinated','Fused'))
View(t2)
library(lme4)
?glmer
summary(glmer(finished ~ Verb*Pronoun, data = t2, family = 'binomial'))
summary(glm(finished ~ Verb*Pronoun, data = t2, family = 'binomial'))
summary(glm(finished ~ Verb+Pronoun, data = t2, family = 'binomial'))
knitr::opts_chunk$set(echo = TRUE)
## getting the data
data_exp1 = read.csv("/Users/cognation/Google Drive/03-Writing&Presenting/2020_JoML_Isofusi/package-prep/01_data/exps_combined_files/isofusi_exp3_combined.csv")
## calculating the number of blocks per participant
dd_data_exp1 = ddply(data_exp1, c('condition','subj_number'), summarise, learningBlockNumber = floor((length(trial_index) - 7 - 17)/25), age = unique(participant_age)[2], gender = unique(participant_gender)[2]) ## floor because of additional debrief about whether they have taken linguistics classes that was introduced later on
library(plyr)
library(lme4)
library(lme4)
library(emmeans)
library(ggplot2)
library(lme4)
library(emmeans)
library(ggplot2)
library(stringdist)
knitr::opts_chunk$set(echo = TRUE)
## getting the data
data_exp1 = read.csv("/Users/cognation/Google Drive/03-Writing&Presenting/2020_JoML_Isofusi/package-prep/01_data/exps_combined_files/isofusi_exp3_combined.csv")
## calculating the number of blocks per participant
dd_data_exp1 = ddply(data_exp1, c('condition','subj_number'), summarise, learningBlockNumber = floor((length(trial_index) - 7 - 17)/25), age = unique(participant_age)[2], gender = unique(participant_gender)[2]) ## floor because of additional debrief about whether they have taken linguistics classes that was introduced later on
## getting the data
data_exp1 = read.csv("/Users/cognation/Google Drive/03-Writing&Presenting/2020_JoML_Isofusi/package-prep/01_data/exps_combined_files/isofusi_exp1_combined.csv")
## calculating the number of blocks per participant
dd_data_exp1 = ddply(data_exp1, c('condition','subj_number'), summarise, learningBlockNumber = floor((length(trial_index) - 7 - 17)/25), age = unique(participant_age)[2], gender = unique(participant_gender)[2]) ## floor because of additional debrief about whether they have taken linguistics classes that was introduced later on
## ## >> add info about factors; less complex goes before more complex for left-to-right presentation in graphs
dd_data_exp1$Verb = factor(ifelse(dd_data_exp1$condition %in% c('pn+v','p+n+v','p+v'), 'Concatenated', 'Isolated'), levels = c('Isolated','Concatenated'))
dd_data_exp1$Pronoun = factor(ifelse(dd_data_exp1$condition %in% c('pn+v','pn_v'), 'Fused', ifelse(dd_data_exp1$condition %in% c('p+n+v','p+n_v'), 'Agglutinated', 'No number')), levels = c('No number','Agglutinated','Fused'))
dd_data_exp1$condition = factor(dd_data_exp1$condition, levels = c('p_v','p+n_v','pn_v','p+v','p+n+v','pn+v'))
ggplot(dd_data_exp1, aes(x = Pronoun, y = learningBlockNumber)) + geom_violin(aes(fill = Pronoun))  + geom_boxplot(width = 0.25) + facet_wrap( ~ Verb) + ylab('Number of learning blocks') + xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8)) #+ geom_text(aes(x = Pronouns, y = 1, label = txt), data = text_data)
ggplot(dd_data_exp1, aes(x = Pronoun, y = learningBlockNumber)) + geom_violin(aes(fill = Pronoun))  + geom_boxplot(width = 0.25) + facet_wrap( ~ Verb) + ylab('Number of learning blocks') + xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8)) + geom_text(aes(x = Pronouns, y = 1, label = txt), data = text_data)
ggplot(dd_data_exp1, aes(x = Pronoun, y = learningBlockNumber)) + geom_violin(aes(fill = Pronoun))  + geom_boxplot(width = 0.25) + facet_wrap( ~ Verb) + ylab('Number of learning blocks') + xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8)) + geom_text(aes(x = Pronouns, y = 1, label = condition))
ggplot(dd_data_exp1, aes(x = Pronoun, y = learningBlockNumber)) + geom_violin(aes(fill = Pronoun))  + geom_boxplot(width = 0.25) + facet_wrap( ~ Verb) + ylab('Number of learning blocks') + xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8)) + geom_text(aes(x = Pronoun, y = 1, label = condition))
ggplot(dd_data_exp1, aes(x = Pronoun, y = learningBlockNumber)) + geom_violin(aes(fill = Pronoun))  + geom_boxplot(width = 0.25) + facet_wrap( ~ Verb) + ylab('Number of learning blocks') + xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8)) + geom_text(aes(x = Pronoun, y = 1, label = condition))
poisson.exp1.all.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1, family = 'poisson')
Anova(poisson.exp1.all.ppts)
library(plyr)
library(lme4)
library(emmeans)
library(ggplot2)
library(stringdist)
library(car)
poisson.exp1.all.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1, family = 'poisson')
Anova(poisson.exp1.all.ppts)
knitr::opts_chunk$set(echo = TRUE, tidy.opts=list(width.cutoff=80),tidy=TRUE)
knitr::opts_chunk$set(echo = TRUE)
## getting the data
data_exp1 = read.csv("/Users/cognation/Google Drive/03-Writing&Presenting/2020_JoML_Isofusi/package-prep/01_data/exps_combined_files/isofusi_exp1_combined.csv")
## calculating the number of blocks per participant
dd_data_exp1 = ddply(data_exp1, c('condition','subj_number'), summarise, learningBlockNumber = floor((length(trial_index) - 7 - 17)/25), age = unique(participant_age)[2], gender = unique(participant_gender)[2]) ## floor because of additional debrief about whether they have taken linguistics classes that was introduced later on
## ## >> add info about factors; less complex goes before more complex for left-to-right presentation in graphs
dd_data_exp1$Verb = factor(ifelse(dd_data_exp1$condition %in% c('pn+v','p+n+v','p+v'), 'Concatenated', 'Isolated'), levels = c('Isolated','Concatenated'))
dd_data_exp1$Pronoun = factor(ifelse(dd_data_exp1$condition %in% c('pn+v','pn_v'), 'Fused', ifelse(dd_data_exp1$condition %in% c('p+n+v','p+n_v'), 'Agglutinated', 'No number')), levels = c('No number','Agglutinated','Fused'))
dd_data_exp1$condition = factor(dd_data_exp1$condition, levels = c('p_v','p+n_v','pn_v','p+v','p+n+v','pn+v'))
poisson.exp1.all.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1, family = 'poisson')
Anova(poisson.exp1.all.ppts)
mean(dd_data_exp1$learningBlockNumber)
mean(dd_data_exp1$learningBlockNumber)
var(dd_data_exp1$learningBlockNumber)
emmeans(poisson.exp1.all.ppts, pairwise ~ Pronoun | Verb)
knitr::opts_chunk$set(echo = TRUE)
mean(dd_data_exp1$learningBlockNumber)
var(dd_data_exp1$learningBlockNumber)
poisson.exp1.all.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1, family = 'poisson')
Anova(poisson.exp1.all.ppts)
quasipoisson.exp1.all.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1, family = 'quasipoisson')
Anova(quasipoisson.exp1.all.ppts)
mean(dd_data_exp1$learningBlockNumber)
var(dd_data_exp1$learningBlockNumber)
summary(poisson.exp1.all.ppts)
install.packges('AER')
install.packages('AER')
library(AER)
?dispersiontest
mean(dd_data_exp1$learningBlockNumber)
var(dd_data_exp1$learningBlockNumber)
dispersiontest(poisson.exp1.all.ppts, trafo = 1)
emmeans(quasipoisson.exp1.all.ppts, pairwise ~ Pronoun)
emmeans(quasipoisson.exp1.all.ppts, pairwise ~ Pronoun | Verb)
## adding accuracy to dd_data_exp1
exp1_responses = data_exp1[data_exp1$trial_type == "survey-text-enter-noblank-plus-feedback-isofusi",]
exp1_responses$internal_node_id = as.character(exp1_responses$internal_node_id)
exp1_responses = exp1_responses[grepl("^0.0-8.0",exp1_responses$internal_node_id),]
exp1_responses$was_answer_correct = ifelse(exp1_responses$was_answer_correct == "true", T, F)
exp1_dd_correct = ddply(exp1_responses, c("subj_number","condition"), summarise, accuracy = sum(was_answer_correct))
dd_data_exp1 = join(dd_data_exp1, exp1_dd_correct)
View(dd_data_exp1)
ggplot(dd_data_exp1[dd_data_exp1$accuracy == 6,], aes(x = Pronoun, y = learningBlockNumber)) + geom_violin(aes(fill = Pronoun))  + geom_boxplot(width = 0.25) + facet_wrap( ~ Verb) + ylab('Number of learning blocks') + xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8)) + geom_text(aes(x = Pronoun, y = 1, label = condition))
poisson.exp1.only6.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1[dd_data_exp1$accuracy == 6,], family = 'poisson')
Anova(poisson.exp1.only6.ppts)
emmeans(poisson.exp1.only6.ppts, pairwise ~ Pronoun | Verb)
emmeans(poisson.exp1.only6.ppts, pairwise ~ Pronoun)
mean(dd_data_exp1$learningBlockNumber)
var(dd_data_exp1$learningBlockNumber)
dispersiontest(poisson.exp1.only6.ppts, trafo = 1)
mean(dd_data_exp1[dd_data_exp1$accuracy == 6,'learningBlockNumber'])
var(dd_data_exp1[dd_data_exp1$accuracy == 6,'learningBlockNumber'])
dispersiontest(poisson.exp1.only6.ppts, trafo = 1)
mean(dd_data_exp1$learningBlockNumber)
var(dd_data_exp1$learningBlockNumber)
dispersiontest(poisson.exp1.only6.ppts, trafo = 1)
mean(dd_data_exp1[dd_data_exp1$accuracy == 6,'learningBlockNumber'])
var(dd_data_exp1[dd_data_exp1$accuracy == 6,'learningBlockNumber'])
dispersiontest(poisson.exp1.only6.ppts, trafo = 1)
quasipoisson.exp1.only6.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1[dd_data_exp1$accuracy == 6,], family = 'quasipoisson')
Anova(quasipoisson.exp1.only6.ppts)
emmeans(quasipoisson.exp1.only6.ppts, pairwise ~ Pronoun)
ggplot(dd_data_exp1[dd_data_exp1$accuracy == 6,], aes(x = Pronoun, y = learningBlockNumber)) + geom_violin(aes(fill = Pronoun))  + geom_boxplot(width = 0.25) + ylab('Number of learning blocks') + xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8)) + geom_text(aes(x = Pronoun, y = 1, label = condition))
?Anova
poisson.exp1.only6.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1[dd_data_exp1$accuracy == 6,], family = 'poisson')
Anova(poisson.exp1.only6.ppts)
poisson.exp1.all.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1, family = 'poisson')
Anova(poisson.exp1.all.ppts)
poisson.exp1.all.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1, family = 'poisson')
Anova(poisson.exp1.all.ppts, type = 'III')
quasipoisson.exp1.all.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1, family = 'quasipoisson')
Anova(quasipoisson.exp1.all.ppts, type = 3)
quasipoisson.exp1.all.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1, family = 'quasipoisson')
Anova(quasipoisson.exp1.all.ppts)
poisson.exp1.only6.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1[dd_data_exp1$accuracy == 6,], family = 'poisson')
Anova(poisson.exp1.only6.ppts, type = 3)
?emmeans
emmeans
poisson.exp1.only6.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1[dd_data_exp1$accuracy == 6,], family = 'poisson')
Anova(poisson.exp1.only6.ppts, type = 3)
poisson.exp1.only6.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1[dd_data_exp1$accuracy == 6,], family = 'poisson')
Anova(poisson.exp1.only6.ppts)
quasipoisson.exp1.only6.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1[dd_data_exp1$accuracy == 6,], family = 'quasipoisson')
Anova(quasipoisson.exp1.only6.ppts, type = 3)
quasipoisson.exp1.only6.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1[dd_data_exp1$accuracy == 6,], family = 'quasipoisson')
Anova(quasipoisson.exp1.only6.ppts)
summary(quasipoisson.exp1.all.ppts)
ggplot(dd_data_exp1, aes(x = Pronoun, y = learningBlockNumber)) + geom_violin(aes(fill = Pronoun))  + geom_boxplot(width = 0.25) + facet_wrap( ~ Verb) + ylab('Number of learning blocks') + xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8)) + geom_text(aes(x = Pronoun, y = 1, label = condition))
summary(quasipoisson.exp1.only6.ppts)
quasipoisson.exp1.only6.ppts = glm(learningBlockNumber ~ Pronoun*Verb, data = dd_data_exp1[dd_data_exp1$accuracy == 6,], family = 'quasipoisson')
Anova(quasipoisson.exp1.only6.ppts, type = 3)
ggplot(dd_data_exp1, aes(x = Pronoun, y = learningBlockNumber)) + geom_violin(aes(fill = Pronoun))  + geom_boxplot(width = 0.25) + ylab('Number of learning blocks') + xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8)) + geom_text(aes(x = Pronoun, y = 1, label = condition))
ggplot(dd_data_exp1, aes(x = Verb, y = learningBlockNumber)) + geom_violin(aes(fill = Pronoun))  + geom_boxplot(width = 0.25) + ylab('Number of learning blocks') + geom_text(aes(x = Pronoun, y = 1, label = condition)) #+ xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8))
ggplot(dd_data_exp1, aes(x = Verb, y = learningBlockNumber)) + geom_violin(aes(fill = Verb))  + geom_boxplot(width = 0.25) + ylab('Number of learning blocks') + geom_text(aes(x = Pronoun, y = 1, label = condition)) #+ xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8))
ggplot(dd_data_exp1[dd_data_exp1$accuracy == 6,], aes(x = Verb, y = learningBlockNumber)) + geom_violin(aes(fill = Verb))  + geom_boxplot(width = 0.25) + ylab('Number of learning blocks') + geom_text(aes(x = Pronoun, y = 1, label = condition)) #+ xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8))
ggplot(dd_data_exp1, aes(x = Verb, y = learningBlockNumber)) + geom_violin(aes(fill = Verb))  + geom_boxplot(width = 0.25) + ylab('Number of learning blocks') + geom_text(aes(x = Pronoun, y = 1, label = condition)) #+ xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8))
ggplot(dd_data_exp1, aes(x = Verb, y = learningBlockNumber)) + geom_violin(aes(fill = Verb))  + geom_boxplot(width = 0.25) + ylab('Number of learning blocks') + geom_text(aes(x = Verb, y = 1, label = condition)) #+ xlab('Pronoun: Form-to-meaning mapping transparency of\nPerson and number in pronoun') + labs(fill = 'Person and number\nin pronoun') + theme(axis.text.x = element_text(size = 8))
## analysis 1, as above
Anova(quasipoisson.exp1.all.ppts, type = 2)
## analysis 1, type 3
Anova(quasipoisson.exp1.all.ppts, type = 3)
## analysis 2, as above
Anova(quasipoisson.exp1.only6.ppts, type = 2)
## analysis 2, type 3
Anova(quasipoisson.exp1.only6.ppts, type = 3)
devtools::install_github("crsh/papaja")
install.packages("broom")
devtools::install_github("crsh/papaja")
rmarkdown::pandoc_version()
rmarkdown::pandoc_version()
devtools::install_github("ThinkR-open/remedy")
remedy::set_hotkeys
?remedy::set_hotkeys
library(remedy)
?remedy::set_hotkeys
??remedy::set_hotkeys
?set_hotkeys
??set_hotkeys
rm(list = ls())
view = View
library(ggplot2)
library(plyr)
se = function(x) sqrt(var(x)/length(x))
library(PSYC201)
setwd("~/Google Drive/06-Projects/I-Complexity-UniMorph/01_data")
## ## 19/03/02 - note that those weren't all the available files, you preemtively didn't put some file that obviously had issues here
files = list.files()
files
dataset = list()
for (i in files) {
print(i)
dataset[[i]] = read.delim(i, as.is = T, blank.lines.skip = T, header = F, encoding = 'UTF-8')#, comment.char = '\n')
}
view=View
view(dataset[["eng.txt"]])
dim(dataset)
dim(dataset[['fin.1.txt']])
dim(dataset[['fin.2.txt']])
dim(dataset[['eng.txt']])
view(dataset[['fin.1.txt']])
levels(dataset[['fin.1.txt']]$V3)
unique(dataset[['fin.1.txt']]$V3)
## make one dataset out of fin.1 and fin.2, then remove them
dataset[['fin.txt']] = rbind(dataset[['fin.1.txt']],dataset[['fin.2.txt']])
'fin.txt' %in% names(dataset)
dataset[['fin.1.txt']] = NULL
dataset[['fin.2.txt']] = NULL
## save session
library(session)
install.packages(session)
install.packages('session')
## save session
library(session)
## get rid of those languages that don't have any nouns
d2 = dataset
temp = names(d2)
temp
i = temp[1]
i
view(d2[[i]])
levels(as.factor(c(1,2,3,6,3,4,2,1,4,56,4,3)))
unique(c(1,2,3,6,3,4,2,1,4,56,4,3)
)
unique
as.factor
?grepl
grepl(1,1:10)
1:10
grepl(1,1:10)
T %in% grepl(1,1:10)
## get rid of those languages that don't have any nouns
d2 = dataset
temp = names(d2)
for (i in temp) {
print(i)
temp2 = unique(d2[[i]]$V3)
if (! (T %in% grepl('^N;',temp2))) {d2[[i]] = NULL}
}
unique(d2[['ady.txt']]$V3)
i = names(d2)[1]
i
print(i)
d2[[i]]$V3f = as.factor(d2[[i]]$V3)
view(d2[[i]])
temp = levels(d2[[i]]$V3f)
temp
grepl('^N;',temp)
temp[grepl('^N;',temp)]
temp
grepl('^N;|;N;|;N$',temp)
grepl('^N;|;N;|;N$',c(temp,'INS;N;SG','INS;SG;N','INS;ADJ'))
## for all the other ones - leave in only nouns
for (i in names(d2)) {
print(i)
temp = unique(d2[[i]]$V3)
temp = temp[grepl('^N;|;N;|;N$',temp)] ## are all of them in the beginning? check later
d2[[i]] = subset(d2[[i]], V3 %in% temp)
d2[[i]]$V3f = as.factor(d2[[i]]$V3)
print(levels(d2[[i]]$V3f))
}
d3 = d2
view(d3[['eng.txt']])
view(d3[['fin.txt']])
## remove lemmas with spaces or numbers in them
for (i in names(d3)) {
print(i)
d3[[i]] = subset(d3[[i]], ! grepl('[[:blank:]|[:digit:]]',V1))
}
view(d3[['fin.txt']])
## how many lemmas are there in each language?
how_many_nouns = data.frame(lang = names(d3), hmn = 0)
View(how_many_nouns)
for (i in names(d3)) {
print(i)
how_many_nouns[how_many_nouns$lang == i,2] = length(unique(d3[[i]]$V1))
}
view(d3[['gml.txt']])
## ok, for now let's limit ourselves to cases where there's > 100 lemmas
d4 = d3
how_many_nouns[how_many_nouns$hmn > 100,1]
## ok, for now let's limit ourselves to cases where there's > 100 lemmas
d4 = d3
temp = as.character(how_many_nouns[how_many_nouns$hmn > 100,1])
d4 = d4[temp]
names(d4)
d4[['ady.txt']]
view(d4[['ady.txt']])
i = 'ady.txt'
as.character(levels(d4[[i]]$V3f))
temp = as.character(levels(d4[[i]]$V3f))
?setequal
setequal(c(1,2),c(1,2))
setequal(c(1,2),c(3,2))
setequal(c(1,2),c(2,1))
setequal(c(1:10),c(10:1))
1:10
10:1
setequal(c(1:10),c(10:1,50))
setequal(c(1:10),c(10:1,1))
c(1:10)
c(10:1,1)
test = list()
for (i in names(d4)) {
print(i)
temp = as.character(levels(d4[[i]]$V3f))
test[[i]] = ddply(d4[[i]], c('V1'), summarise, num_cells = length(V3), levelssame = setequal(as.character(levels(as.factor(V3))),temp))
test[[i]]$hmc = length(levels(as.factor(d4[[i]]$V3)))
test[[i]]$hmcsame = (test[[i]]$num_cells == test[[i]]$hmc)
}
for (i in names(test)) {
test[[i]]$same = (test[[i]]$levelssame & test[[i]]$hmcsame)
}
view(d4[['ady.txt']])
view(test[['ady.txt']])
table(test[['ady.txt']]$num_cells)
test2 = data.frame(lang = names(test), how_many_same = 0, how_many_nouns = how_many_nouns[match(names(test),how_many_nouns$lang),'hmn'])
for (i in names(test)) {
test2[test2$lang == i, 'how_many_same'] = sum(test[[i]]$same)
}
view(test2)
